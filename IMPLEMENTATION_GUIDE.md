# Implementation Guide - AI Agent with Long-term Memory

## [object Object] Completion Summary

Báº¡n Ä‘Ã£ cÃ³ má»™t há»‡ thá»‘ng AI Agent hoÃ n chá»‰nh vá»›i cÃ¡c tÃ­nh nÄƒng:

### âœ… HoÃ n thÃ nh
1. **Agent Core** - TÃ­ch há»£p OpenAI GPT-4
2. **Long-term Memory** - FAISS Vector Database
3. **RAG Pipeline** - Extract â†’ Judge â†’ Embed â†’ Store â†’ Retrieve
4. **Knowledge Management** - Tá»± Ä‘á»™ng trÃ­ch xuáº¥t vÃ  lÆ°u trá»¯
5. **Duplicate Detection** - Chá»‘ng trÃ¹ng láº·p thÃ´ng minh
6. **Configurable Personality** - TÃ¹y chá»‰nh tÃªn, tuá»•i, giá»›i tÃ­nh, ngÃ´n ngá»¯, tÃ­nh cÃ¡ch
7. **Tool System** - Má»Ÿ rá»™ng Ä‘Æ°á»£c vá»›i cÃ¡c cÃ´ng cá»¥ tÃ¹y chá»‰nh
8. **Gradio UI** - Giao diá»‡n web thÃ¢n thiá»‡n

## ðŸš€ Getting Started

### Step 1: Setup Environment

```bash
# Clone hoáº·c táº¡o project
mkdir ai-agent && cd ai-agent

# Táº¡o virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Setup environment variables
echo "OPENAI_API_KEY=your_key_here" > .env
```

### Step 2: Configure Agent

Edit `config.yaml`:

```yaml
agent:
  name: "Luna"              # TÃªn agent
  age: 25                  # Tuá»•i
  gender: "female"         # Giá»›i tÃ­nh
  language: "vi"           # NgÃ´n ngá»¯ (vi, en, ja, zh)
  personality: "friendly"  # TÃ­nh cÃ¡ch
  speaking_style: "natural"  # Phong cÃ¡ch nÃ³i

openai:
  api_key: "${OPENAI_API_KEY}"
  model: "gpt-4"
  temperature: 0.7
  max_tokens: 2048

knowledge:
  max_entries: 10000
  similarity_threshold: 0.85  # NgÆ°á»¡ng phÃ¡t hiá»‡n trÃ¹ng láº·p
  min_confidence: 0.6         # Äá»™ tin cáº­y tá»‘i thiá»ƒu
```

### Step 3: Run Agent

#### Option A: Gradio UI (Recommended)
```bash
python main.py --mode ui
# Truy cáº­p http://localhost:7860
```

#### Option B: CLI Mode
```bash
python main.py --mode cli
```

#### Option C: Python Script
```python
from src.agent import AIAgent

agent = AIAgent("config.yaml")
result = agent.process_message("Xin chÃ o!")
print(result["response"])
```

## ðŸ“š Usage Examples

### Example 1: Basic Chat

```python
from src.agent import AIAgent

agent = AIAgent("config.yaml")

# Chat - tá»± Ä‘á»™ng trÃ­ch xuáº¥t kiáº¿n thá»©c
result = agent.process_message(
    "Python lÃ  ngÃ´n ngá»¯ láº­p trÃ¬nh Ä‘Æ°á»£c táº¡o bá»Ÿi Guido van Rossum"
)

print(f"Response: {result['response']}")
print(f"Stored: {len(result['knowledge_extraction']['stored'])} entries")
```

### Example 2: RAG Retrieval

```python
# ThÃªm kiáº¿n thá»©c
agent.add_knowledge("Viá»‡t Nam náº±m á»Ÿ ÄÃ´ng Nam Ã")
agent.add_knowledge("Thá»§ Ä‘Ã´ cá»§a Viá»‡t Nam lÃ  HÃ  Ná»™i")

# Query - tá»± Ä‘á»™ng láº¥y context tá»« knowledge base
result = agent.process_message("Viá»‡t Nam á»Ÿ Ä‘Ã¢u?")

# Kiáº¿n thá»©c liÃªn quan Ä‘Æ°á»£c tá»± Ä‘á»™ng sá»­ dá»¥ng trong response
print(result["rag_context"])  # Xem kiáº¿n thá»©c Ä‘Æ°á»£c láº¥y
```

### Example 3: Update Configuration

```python
# Thay Ä‘á»•i tÃ­nh cÃ¡ch agent
agent.update_config(
    name="Sakura",
    personality="professional",
    language="en"
)

# Xem cáº¥u hÃ¬nh hiá»‡n táº¡i
config = agent.get_config()
print(config)
```

### Example 4: Knowledge Management

```python
# ThÃªm kiáº¿n thá»©c thá»§ cÃ´ng
success, entry_id = agent.add_knowledge(
    "Machine Learning lÃ  nhÃ¡nh cá»§a AI",
    source="manual",
    confidence=0.95
)

# Xem thá»‘ng kÃª
stats = agent.get_knowledge_stats()
print(f"Total: {stats['total_entries']}")
print(f"Active: {stats['active_entries']}")

# XÃ³a táº¥t cáº£ kiáº¿n thá»©c
agent.clear_knowledge()
```

### Example 5: Tool Usage

```python
from src.tools import ToolManager

tool_manager = ToolManager(agent.rag_pipeline)

# DÃ¹ng calculator
result = tool_manager.execute_tool("calculator", expression="2 + 2 * 3")
print(result["result"])  # 8

# Query knowledge base
result = tool_manager.execute_tool("knowledge_base", query="Python")
print(result["results"])
```

## ðŸ”§ Advanced Configuration

### Knowledge Management Tuning

```yaml
knowledge:
  # Sá»‘ lÆ°á»£ng kiáº¿n thá»©c tá»‘i Ä‘a
  max_entries: 10000
  
  # NgÆ°á»¡ng phÃ¡t hiá»‡n trÃ¹ng láº·p (0-1)
  # Cao = kháº¯t khe hÆ¡n, Ã­t lÆ°u trÃ¹ng
  # Tháº¥p = dá»… lÆ°u trÃ¹ng hÆ¡n
  similarity_threshold: 0.85
  
  # Äá»™ tin cáº­y tá»‘i thiá»ƒu Ä‘á»ƒ lÆ°u (0-1)
  # Cao = chá»‰ lÆ°u kiáº¿n thá»©c cháº¯c cháº¯n
  # Tháº¥p = lÆ°u nhiá»u kiáº¿n thá»©c hÆ¡n
  min_confidence: 0.6
  
  # Thá»i gian lÆ°u (ngÃ y)
  retention_days: 365
```

### RAG Pipeline Tuning

```yaml
rag:
  # Sá»‘ kiáº¿n thá»©c láº¥y cho má»—i query
  top_k: 5
  
  # KÃ­ch thÆ°á»›c chunk khi xá»­ lÃ½ text
  chunk_size: 512
  
  # Overlap giá»¯a cÃ¡c chunk
  chunk_overlap: 50
```

### OpenAI Tuning

```yaml
openai:
  model: "gpt-4"  # hoáº·c "gpt-3.5-turbo"
  
  # SÃ¡ng táº¡o (0-2): 0=xÃ¡c Ä‘á»‹nh, 1=cÃ¢n báº±ng, 2=sÃ¡ng táº¡o
  temperature: 0.7
  
  # Sá»‘ token tá»‘i Ä‘a
  max_tokens: 2048
  
  # Diversity (0-1)
  top_p: 0.9
```

## ðŸ› ï¸ Extending the System

### Add Custom Tool

```python
from src.tools import Tool

class WeatherTool(Tool):
    def execute(self, city: str, **kwargs):
        # Implement weather API call
        return {
            "city": city,
            "temperature": 25,
            "condition": "sunny"
        }
    
    def get_description(self):
        return "Get weather information for a city"

# Register tool
from src.agent import AIAgent
agent = AIAgent("config.yaml")
agent.rag_pipeline.tool_manager.register_tool("weather", WeatherTool())

# Use tool
result = agent.rag_pipeline.tool_manager.execute_tool("weather", city="Hanoi")
```

### Custom Knowledge Extraction

```python
from src.knowledge_extractor import KnowledgeExtractor

class CustomExtractor(KnowledgeExtractor):
    def extract_from_text(self, text, source="chat"):
        # Custom extraction logic
        # CÃ³ thá»ƒ sá»­ dá»¥ng regex, NLP, v.v.
        extractions = []
        # ... implementation ...
        return extractions

# Use custom extractor
agent.rag_pipeline.extractor = CustomExtractor()
```

### Custom Vector DB

```python
# Thay tháº¿ FAISS báº±ng Milvus, Pinecone, v.v.
# Implement interface tÆ°Æ¡ng tá»± VectorDB

class MilvusDB:
    def add_entry(self, content, source, confidence, metadata):
        # Milvus implementation
        pass
    
    def find_similar(self, text, top_k):
        # Milvus implementation
        pass

# Use custom DB
agent.rag_pipeline.vector_db = MilvusDB()
```

## ðŸ“Š Monitoring & Debugging

### View Logs

```bash
# Real-time logs
tail -f logs/agent.log

# Search logs
grep "ERROR" logs/agent.log
grep "knowledge" logs/agent.log
```

### Debug Mode

```python
import logging

# Enable debug logging
logging.basicConfig(level=logging.DEBUG)

agent = AIAgent("config.yaml")
result = agent.process_message("Test")
```

### Performance Monitoring

```python
import time

# Measure response time
start = time.time()
result = agent.process_message("Test")
elapsed = time.time() - start

print(f"Response time: {elapsed:.2f}s")
print(f"Knowledge stored: {len(result['knowledge_extraction']['stored'])}")
print(f"Context retrieved: {result['rag_context']['retrieved_count']}")
```

## [object Object] Deployment

### Security Checklist

- [ ] Use environment variables for API keys
- [ ] Enable HTTPS for web interface
- [ ] Implement authentication/authorization
- [ ] Encrypt sensitive data
- [ ] Set up rate limiting
- [ ] Monitor API usage
- [ ] Regular backups of knowledge base
- [ ] Input validation and sanitization

### Performance Optimization

```python
# 1. Use embedding cache
embedding_manager.clear_cache()  # Periodic cleanup

# 2. Batch process multiple texts
embeddings = embedding_manager.embed_texts(texts)

# 3. Use appropriate FAISS index
# For 1M vectors: "IVF4096,Flat"
# For 100M vectors: "IVF65536,Flat"

# 4. Implement pagination for large results
results = vector_db.find_similar(query, top_k=100)
```

### Scaling Strategies

```
Single Agent (Current)
    â†“
Multiple Agents (Same Server)
    â†“
Distributed Agents (Multiple Servers)
    â†“
Multi-region Deployment
```

## ðŸ§ª Testing

### Run Tests

```bash
python test_agent.py
```

### Write Custom Tests

```python
import unittest
from src.agent import AIAgent

class TestMyAgent(unittest.TestCase):
    def setUp(self):
        self.agent = AIAgent("config.yaml")
    
    def test_chat(self):
        result = self.agent.process_message("Test")
        self.assertIsNotNone(result["response"])
    
    def test_knowledge_extraction(self):
        result = self.agent.process_message("New knowledge")
        self.assertGreater(len(result["knowledge_extraction"]["extracted"]), 0)

if __name__ == "__main__":
    unittest.main()
```

## ðŸ“ˆ Performance Metrics

### Typical Performance

| Operation | Time | Notes |
|-----------|------|-------|
| Embed text | 0.5-1s | API call |
| Search similar | 10-50ms | FAISS search |
| Judge knowledge | 1-2s | LLM call |
| Generate response | 2-5s | GPT-4 call |
| Full pipeline | 5-10s | All steps |

### Optimization Tips

1. **Cache embeddings** - Avoid re-embedding same text
2. **Batch operations** - Process multiple items together
3. **Use GPU** - For FAISS index operations
4. **Async processing** - Non-blocking operations
5. **Connection pooling** - Reuse API connections

## [object Object]

### Issue: "OPENAI_API_KEY not set"
```bash
# Solution: Set environment variable
export OPENAI_API_KEY="your-key-here"
# or create .env file
echo "OPENAI_API_KEY=your-key-here" > .env
```

### Issue: FAISS index errors
```bash
# Solution: Reset database
rm -rf data/vector_db/
# Restart agent
```

### Issue: Slow responses
```python
# Check performance
stats = agent.get_knowledge_stats()
print(f"Index size: {stats['index_size']}")

# If too large, implement cleanup
agent.clear_knowledge()
```

### Issue: Memory usage high
```python
# Clear embedding cache
agent.rag_pipeline.embedding_manager.clear_cache()

# Reduce max_entries in config
# Implement periodic cleanup
```

## ðŸ“š Additional Resources

- [OpenAI Documentation](https://platform.openai.com/docs)
- [FAISS Documentation](https://github.com/facebookresearch/faiss)
- [Gradio Documentation](https://gradio.app)
- [RAG Papers](https://arxiv.org/search/?query=retrieval+augmented+generation)
- [Vector Database Comparison](https://github.com/erikbern/ann-benchmarks)

## ðŸŽ“ Learning Path

1. **Beginner**: Run UI, chat with agent
2. **Intermediate**: Modify config, add custom tools
3. **Advanced**: Implement custom extractors, use different vector DB
4. **Expert**: Deploy to production, scale to multiple agents

## ðŸ“ž Support

For issues and questions:
1. Check logs: `logs/agent.log`
2. Review examples: `example_usage.py`
3. Read documentation: `ARCHITECTURE.md`
4. Check tests: `test_agent.py`

---

**Happy coding! ðŸš€**

