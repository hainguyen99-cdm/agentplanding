# ğŸ¤– AI Agent with Long-term Memory

An intelligent AI agent with OpenAI integration, long-term memory management using Vector Database (FAISS), and RAG (Retrieval-Augmented Generation) pipeline.

## âœ¨ Features

### Core Features
- âœ… **OpenAI Integration**: Uses GPT-4 for intelligent responses
- âœ… **Long-term Memory**: FAISS-based vector database for knowledge storage
- âœ… **RAG Pipeline**: Extract â†’ Judge â†’ Embed â†’ Store â†’ Retrieve
- âœ… **Automatic Knowledge Extraction**: Automatically extracts knowledge from conversations
- âœ… **Duplicate Detection**: Prevents storing duplicate or similar knowledge
- âœ… **Noise Filtering**: Filters out low-confidence or irrelevant information
- âœ… **Configurable Personality**: Customize agent name, age, gender, language, personality, and speaking style
- âœ… **Tool Integration**: Extensible tool system (calculator, knowledge base, etc.)
- âœ… **Gradio UI**: User-friendly web interface

### Architecture

```
User Input
    â†“
Knowledge Extraction (LLM)
    â†“
Judgment (Should store?)
    â†“
Embedding (OpenAI)
    â†“
Duplicate Detection (FAISS)
    â†“
Storage (FAISS Vector DB)
    â†“
Retrieval (RAG for queries)
    â†“
Response Generation (GPT-4)
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone repository
git clone <repo-url>
cd ai-agent

# Install dependencies
pip install -r requirements.txt

# Create .env file
cp .env.example .env
# Edit .env and add your OpenAI API key
```

### 2. Configuration

Edit `config.yaml` to customize your agent:

```yaml
agent:
  name: "Luna"           # Agent name
  age: 25               # Agent age
  gender: "female"      # Agent gender
  language: "vi"        # Language (vi, en, ja, zh)
  personality: "friendly"  # Personality type
  speaking_style: "natural"  # Speaking style

openai:
  api_key: "${OPENAI_API_KEY}"
  model: "gpt-4"
  temperature: 0.7
  max_tokens: 2048
```

### 3. Run the Agent

#### Gradio UI (Recommended)
```bash
python main.py --mode ui
```

#### CLI Mode
```bash
python main.py --mode cli
```

## ğŸ“š Usage Examples

### Basic Chat with Knowledge Extraction

```python
from src.agent import AIAgent

agent = AIAgent("config.yaml")

# Chat - automatically extracts and stores knowledge
result = agent.process_message(
    "Python lÃ  má»™t ngÃ´n ngá»¯ láº­p trÃ¬nh máº¡nh máº½"
)

print(result["response"])
print(f"Stored {len(result['knowledge_extraction']['stored'])} entries")
```

### RAG Retrieval

```python
# Add knowledge
agent.add_knowledge("Viá»‡t Nam lÃ  quá»‘c gia á»Ÿ ÄÃ´ng Nam Ã")
agent.add_knowledge("Thá»§ Ä‘Ã´ cá»§a Viá»‡t Nam lÃ  HÃ  Ná»™i")

# Query with RAG
result = agent.process_message("Viá»‡t Nam á»Ÿ Ä‘Ã¢u?")

# Retrieved context is automatically used in response
print(result["rag_context"])
```

### Update Agent Configuration

```python
# Change agent personality
agent.update_config(
    name="Sakura",
    personality="professional",
    language="en"
)

# Get current config
config = agent.get_config()
print(config)
```

### Knowledge Management

```python
# Add manual knowledge
success, entry_id = agent.add_knowledge(
    "Machine Learning lÃ  nhÃ¡nh cá»§a AI",
    source="manual",
    confidence=0.95
)

# Get statistics
stats = agent.get_knowledge_stats()
print(f"Total entries: {stats['total_entries']}")

# Clear knowledge
agent.clear_knowledge()
```

## ğŸ—ï¸ Project Structure

```
ai-agent/
â”œâ”€â”€ config.yaml              # Configuration file
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ example_usage.py        # Usage examples
â”œâ”€â”€ README.md              # This file
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.py           # Configuration management
    â”œâ”€â”€ agent.py            # Main AI Agent
    â”œâ”€â”€ embeddings.py       # Embedding generation
    â”œâ”€â”€ vector_db.py        # FAISS Vector Database
    â”œâ”€â”€ knowledge_extractor.py  # Knowledge extraction & judgment
    â”œâ”€â”€ rag_pipeline.py     # RAG pipeline
    â”œâ”€â”€ tools.py            # Tool implementations
    â””â”€â”€ ui.py               # Gradio UI
```

## ğŸ”§ Components

### 1. **Agent** (`agent.py`)
Main orchestrator that coordinates all components:
- Manages conversation history
- Processes messages through RAG pipeline
- Extracts knowledge from responses
- Handles configuration

### 2. **Vector Database** (`vector_db.py`)
FAISS-based storage for knowledge:
- Stores embeddings and metadata
- Supports similarity search
- Duplicate detection
- Persistent storage

### 3. **Knowledge Extractor** (`knowledge_extractor.py`)
Intelligent knowledge extraction:
- Extracts knowledge from text using LLM
- Judges if knowledge should be stored
- Evaluates confidence scores
- Filters noise

### 4. **RAG Pipeline** (`rag_pipeline.py`)
Complete RAG workflow:
- Extract â†’ Judge â†’ Embed â†’ Store â†’ Retrieve
- Builds context for responses
- Manages knowledge lifecycle

### 5. **Embeddings** (`embeddings.py`)
Text embedding management:
- Uses OpenAI embedding API
- Caches embeddings
- Computes similarity scores

### 6. **Tools** (`tools.py`)
Extensible tool system:
- Calculator tool
- Knowledge base query tool
- Easy to add new tools

### 7. **UI** (`ui.py`)
Gradio-based web interface:
- Chat interface
- Configuration management
- Knowledge management
- Tool execution

## ğŸ“Š RAG Pipeline Details

### Extract Phase
- LLM analyzes input text
- Identifies knowledge entries
- Extracts key information

### Judge Phase
- Evaluates knowledge quality
- Checks confidence scores
- Determines if worth storing

### Embed Phase
- Converts text to vectors
- Uses OpenAI embeddings
- Caches for efficiency

### Store Phase
- Adds to FAISS index
- Stores metadata
- Persists to disk

### Retrieve Phase
- Searches similar entries
- Ranks by relevance
- Builds context for responses

## ğŸ¯ Configuration Options

### Agent Configuration
- `name`: Agent's name
- `age`: Agent's age
- `gender`: Agent's gender (male, female, other)
- `language`: Primary language (vi, en, ja, zh)
- `personality`: Personality type (friendly, professional, casual, humorous)
- `speaking_style`: Speaking style (natural, formal, casual, poetic)

### Knowledge Configuration
- `max_entries`: Maximum knowledge entries (default: 10000)
- `similarity_threshold`: Threshold for duplicate detection (default: 0.85)
- `min_confidence`: Minimum confidence to store (default: 0.6)
- `retention_days`: How long to keep entries (default: 365)

### RAG Configuration
- `top_k`: Number of entries to retrieve (default: 5)
- `chunk_size`: Text chunk size (default: 512)
- `chunk_overlap`: Overlap between chunks (default: 50)

## ğŸ› ï¸ Extending the Agent

### Add Custom Tool

```python
from src.tools import Tool

class MyCustomTool(Tool):
    def execute(self, **kwargs):
        # Implement your tool logic
        return {"result": "..."}
    
    def get_description(self):
        return "My custom tool description"

# Register tool
agent.rag_pipeline.tool_manager.register_tool("my_tool", MyCustomTool())
```

### Custom Knowledge Extraction

```python
# Override knowledge extraction logic
from src.knowledge_extractor import KnowledgeExtractor

class CustomExtractor(KnowledgeExtractor):
    def extract_from_text(self, text, source="chat"):
        # Custom extraction logic
        pass
```

## ğŸ“ˆ Performance Tips

1. **Embedding Caching**: Embeddings are cached to reduce API calls
2. **Batch Processing**: Process multiple texts together
3. **Index Optimization**: Use appropriate FAISS index type
4. **Duplicate Detection**: Prevents redundant storage
5. **Confidence Filtering**: Only stores high-confidence knowledge

## ğŸ”’ Security Considerations

1. **API Key Management**: Use environment variables, never hardcode
2. **Data Privacy**: Knowledge is stored locally
3. **Access Control**: Implement authentication for production
4. **Input Validation**: Sanitize user inputs

## ğŸ“ Logging

Logs are saved to `logs/agent.log`:

```python
import logging
logger = logging.getLogger(__name__)
logger.info("Message")
logger.error("Error")
```

## [object Object]

### Issue: "OPENAI_API_KEY not set"
**Solution**: Create `.env` file and add your API key

### Issue: FAISS index errors
**Solution**: Delete `data/vector_db/` directory and restart

### Issue: Slow embedding generation
**Solution**: Check internet connection and OpenAI API status

## ğŸ“š References

- [OpenAI API Documentation](https://platform.openai.com/docs)
- [FAISS Documentation](https://github.com/facebookresearch/faiss)
- [Gradio Documentation](https://gradio.app)
- [RAG Papers](https://arxiv.org/search/?query=retrieval+augmented+generation)

## ğŸ“„ License

MIT License

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ Support

For issues and questions, please open an issue on GitHub.

---

**Made with â¤ï¸ for AI enthusiasts**

